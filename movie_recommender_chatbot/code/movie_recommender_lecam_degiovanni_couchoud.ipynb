{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot de Recommandation de Films\n",
    ">**Infos :**\\\n",
    "**Groupe :** Léonie LECAM, Quentin DEGIOVANNI, Matteo COUCHOUD\\\n",
    "**Année universitaire :** 2023-2024 SEMESTRE 1\\\n",
    "**Classe :** ING 3 IA groupe B\\\n",
    "**Matière :** Natural Language Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Gestion du Dataset\n",
    "On commende par importer les libraries et pré-process le dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports :\n",
    "Pour pré-process le dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation des librairies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion des imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération du Dataset\n",
    "On utilise le [MPST Movie Dataset](https://www.kaggle.com/datasets/cryptexcode/mpst-movie-plot-synopses-with-tags) trouvé sur Kaggle.\n",
    "\n",
    "Nous n'utiliserons pas ce dataset à des fins de _fine-tuning_ du LLM que nous importons plus bas.\\\n",
    "Le dataset sera utilisé comme base de données de films connus par le chatbot, pour qu'il puisse recommander des titres de films à partir des préférences de l'utilisateur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle datasets download -d cryptexcode/mpst-movie-plot-synopses-with-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=\"mpst_full_data.csv\",download_mode=\"force_redownload\")\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# On supprime les colonnes inutiles comme 'split', 'imdb_id'\n",
    "df = df.drop(columns=['split', 'imdb_id',\"synopsis_source\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque ligne du dataframe, on concatène le contenu des colonnes plot_synopsis et tags\n",
    "\n",
    "df['description'] = df['plot_synopsis'] + ' ' + df['tags'] + ' ' + df['title']\n",
    "# On supprime les colonnes plot_synopsis et tags\n",
    "df = df.drop(columns=['plot_synopsis', 'tags'])\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les stopwords, la ponctuation, les lettres capitales ainsi que les nombres et les mots de moins de 3 lettres\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def clean_text_description(text):\n",
    "    text = text.lower()\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords])\n",
    "    text = ' '.join([word for word in text.split() if word.isalpha()])\n",
    "    text = ' '.join([word for word in text.split() if len(word) > 2])\n",
    "    return text\n",
    "\n",
    "# Pour la colonne description\n",
    "df['description'] = df['description'].apply(clean_text_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On display les dataframes pour vérifier que tout est ok\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On retire les lignes qui ont un titre ou une description vide\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On display le dataframe pour vérifier que tout est ok\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Algorithme de recommandation de films\n",
    "Dans cette partie, nous définissions une classe _MovieRecommender_ qui permet :\n",
    "- De vectoriser chaque description de titre\n",
    "- De calculer les distances entre chaque vecteurs et les stocker dans une matrice\n",
    "- Prendre en compte la phrase de l'utilisateur afin de calculer sa distance avec les descriptions de films\n",
    "- Retourner jusqu'à 3 films proches de la description donnée par l'utilisateur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition de la classe _MovieRecommender_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé une fonction qui prend en entrée un array, parcours chaque élément et le retire s'il est déjà présent dans l'array\n",
    "def remove_duplicates(array):\n",
    "    new_array = []\n",
    "    for element in array:\n",
    "        if element not in new_array:\n",
    "            new_array.append(element)\n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a class for the MovieRecommender :\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import numpy as np\n",
    "\n",
    "class MovieRecommender:\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.tdfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "        print('test')\n",
    "        # On précalcule la matrice de similarité cosinus\n",
    "        self.tfidf_matrix = self.tdfidf_vectorizer.fit_transform(df['description'])\n",
    "        self.cosine_sim = linear_kernel(self.tfidf_matrix, self.tfidf_matrix)\n",
    "\n",
    "    def get_recommendations(self, user_input):\n",
    "        user_tfidf = self.tdfidf_vectorizer.transform([user_input])\n",
    "        user_cosine_sim = linear_kernel(user_tfidf, self.tfidf_matrix)\n",
    "        # Les indices des 3 films les plus similaires à la description de l'utilisateur\n",
    "        similar_indices = user_cosine_sim.argsort()[0][-4:-1]\n",
    "        # On récupère les scores de similarité\n",
    "        similar_scores = user_cosine_sim[0][similar_indices]\n",
    "        # On récupère les titres des films dans un array\n",
    "        similar_titles = self.df['title'].iloc[similar_indices].values\n",
    "        # On retire les éventuels doublons\n",
    "        similar_titles = remove_duplicates(similar_titles)\n",
    "        \n",
    "        return similar_titles, similar_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation d'un _MovieRecommender_\n",
    "A la création d'une instance de _MovieRecommender_, le classe calcule la matrice de similarité entre toutes les descriptions (tags+synopsis+titre) des films."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée une instance de la classe MovieRecommender\n",
    "movie_recommender = MovieRecommender(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUG : Test d'une recommandation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On teste la méthode get_recommendations\n",
    "\n",
    "recommendations,scores = movie_recommender.get_recommendations(\"a film with pirates in the caribbean\")\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Gestion du LLM\n",
    "Comme LLM, nous utiliserons FLAN-T5 dans sa taille \"_large_\" de Google.\\\n",
    "Le LLM sera utilisé dans la partie conversationnelle du chatbot.\\\n",
    "\n",
    "Pour éviter toute sortie tronquée du LLM, la taille maximale de la sortie est définie à 200 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first need to import Flan-t5-base model and tokenizer\n",
    "model_id = \"google/flan-t5-large\"\n",
    "\n",
    "# We load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# We load the model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "# On veut spécifier au modèle la longueur maximale de la séquence de sortie\n",
    "# On va donc créer un dictionnaire de paramètres\n",
    "# On veut que la longueur maximale de la séquence de sortie soit de 100 tokens\n",
    "\n",
    "params = {\n",
    "    'max_length': 200,\n",
    "    'temperature': 0,\n",
    "    'repetition_penalty': 2.5,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition d'une méthode _Query()_\n",
    "Cette méthode permet d'automatiser la tokenization d'un prompt, la génération et le décodage de sa réponse par le LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On défini une fonction query qui prend en paramètre une requête et qui renvoie une réponse\n",
    "def query(question):\n",
    "    input = question\n",
    "    input_ids = tokenizer.encode(input, return_tensors=\"pt\")\n",
    "    res = model.generate(input_ids, **params)\n",
    "    answer = tokenizer.decode(res[0], skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traitement des prompts de l'utilisateur\n",
    "Dans cette partie, on défini un ensemble de fonctions.\n",
    "Ces fonctions ont pour but de prendre le prompt de l'utlisateur et d'utiliser les fonctionnalité de conversation et compréhension du LLM afin de déterminer si :\n",
    "- L'utilisateur parle de film/demande une recommandation\n",
    "- Lui renvoyer un message d'erreur lorsque le LLM ne comprends pas sa demande/aucun film n'est trouvé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction de traitement : l'utilisateur parle-t-il de films ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def is_about_movies(text):\n",
    "    answer = query(\"\"\"Text: \\”\"\"\"+text+\"\"\"\\\\nGiven the text, tell if the text is about movies. Tell 'NO' if the user did not talk about movies, and 'YES' if the user talked about movies.\"\"\")\n",
    "    print(answer)\n",
    "    if(answer == \"Yes\" or answer == \"yes\" or answer == \"YES\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intro_sentence = query(\"Hello, I am a movie recommendation chatbot. Please describe what kind of film you would like to watch ! Repeat what is written above this last sentence.\")\n",
    "print(intro_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction Array->String\n",
    "Cette fonction permet de passer de l'array retourné par la méthode _get_recommendations()_ de _MovieRecommender_ à une chaine de charactères mise en forme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On créé une fonction pour passer d'un array à une string\n",
    "def array_to_string(array):\n",
    "    string = \"\"\n",
    "    for i in range(len(array)):\n",
    "        string += array[i] + \", \"\n",
    "    return str(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonctions encapsulant le traitement du prompt de l'utilisateur\n",
    "__process_text()__: Cette fonction permet de demander, à chaque prompt de l'utilisateur, de traiter la demande afin d'en comprendre l'intention (demande de recommandation de films) et d'en extraire les données permettant au chatbot de remplir sa fonction première.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On va maintenant créer une fonction qui va traiter le texte donné au LLM, et lui demander de générer un texte en sortie\n",
    "def process_text(text):\n",
    "    # on cherche à savoir si l'utilisateur parle de films\n",
    "    if(is_about_movies(text)):\n",
    "\n",
    "        movies,scores = movie_recommender.get_recommendations(text)\n",
    "        print(array_to_string(movies))\n",
    "        movie_list = array_to_string(movies)\n",
    "        res = query(\"\"\"\n",
    "                    QUERY : Generate a text that lists the following movie titles: The Hobbit, The Lord of the Rings, The Matrix.\n",
    "                    ANSWER : Here are some movie recommendations based on your preferences : The Hobbit, The Lord of the Rings, The Matrix.\n",
    "\n",
    "                    QUERY : Generate a text that lists the following movie titles: Harry Potter and the Prisonner of Askaban, Dune.\n",
    "                    ANSWER : Here are some movie recommendations based on your preferences : Harry Potter and the Prisonner of Askaban, Dune.\n",
    "\n",
    "                    QUERY : QUERY : Generate a text that lists the following movie titles:\"\"\"+movie_list+\"\"\".\n",
    "                    ANSWER : \n",
    "                    \"\"\")    \n",
    "    else:\n",
    "        # On dit à l'utilisateur qu'on n'a pas compris\n",
    "        res = \"Sorry, I could not understand what you said. I am a movie recommendation chatbot. Please describe what kind of film you would like to watch !\"\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Interface Utilisateur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe tkinter\n",
    "import tkinter as tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChatbotGUI:\n",
    "  def __init__(self):\n",
    "    \n",
    "    # On crée une fenêtre\n",
    "    self.root = tk.Tk()\n",
    "    self.root.geometry(\"\")\n",
    "\n",
    "    # On donne une couleur de fond à la fenêtre\n",
    "    self.root.configure(bg=\"#393c4d\")\n",
    "    self.root.title(\"Chatbot - Projet par Léonie LECAM, Quentin DEGIOVANNI et Matteo COUCHOUD - CY-TECH 2023-2024\")\n",
    "\n",
    "    # Create the chatbot's text area\n",
    "    self.text_area = tk.Text(self.root, bg=\"#21232e\", fg=\"white\", width=100, height=21, font=('Montserrat',13), wrap=tk.WORD, padx=10, pady=10)\n",
    "    self.text_area.tag_configure(\"bold\", font=(\"Montserrat\",13,'bold'))\n",
    "    #text_area.pack()\n",
    "    self.text_area.grid(row=0,column=0,columnspan=2)\n",
    "\n",
    "    # Create the user's input field\n",
    "    self.input_field = tk.Entry(self.root, width=89, font=('Montserrat',13), relief=tk.FLAT, border=0, bg=\"#21232e\", fg=\"white\")\n",
    "    #input_field.pack()\n",
    "    self.input_field.grid(row=1,column=0,padx=10,pady=10)\n",
    "\n",
    "    # Create the send button\n",
    "    self.send_button = tk.Button(self.root, text=\"Send\", command=lambda: self.send_message(), font=('Montserrat',13,'bold'), border=0)\n",
    "    #send_button.pack()\n",
    "    self.send_button.grid(row=1,column=1)\n",
    "\n",
    "    # On ajoute une introduction au chatbot dans la fenêtre \n",
    "    self.text_area.insert(tk.END, f\"Chatbot: \", \"bold\")\n",
    "    self.text_area.insert(tk.END, f\"{intro_sentence}\\n\")\n",
    "\n",
    "    # On lance la fenêtre\n",
    "    self.root.mainloop()\n",
    "\n",
    "  def send_message(self):\n",
    "    # Get the user's input\n",
    "    user_input = self.input_field.get()\n",
    "\n",
    "    # Clear the input field\n",
    "    self.input_field.delete(0, tk.END)\n",
    "\n",
    "    # Generate a response from the chatbot\n",
    "    response = process_text(user_input)\n",
    "\n",
    "    # Display the response in the chatbot's text area\n",
    "    self.text_area.insert(tk.END, f\"\\nPrompt: \", \"bold\")\n",
    "    self.text_area.insert(tk.END, f\"{user_input}\\n\\n\")\n",
    "    self.text_area.insert(tk.END, f\"Chatbot: \", \"bold\")\n",
    "    self.text_area.insert(tk.END, f\"{response}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO\n",
      "YES\n",
      "Star Wars: Episode II - Attack of the Clones, Star Wars: Episode I - The Phantom Menace, Star Wars: Episode III - Revenge of the Sith, \n"
     ]
    }
   ],
   "source": [
    "# On lance l'interface du chatbot\n",
    "chatbot_instance = ChatbotGUI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
